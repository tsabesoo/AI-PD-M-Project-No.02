{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Introducing Rasa, the backbone of our innovative chatbot system. Rasa is an open-source conversational AI platform that empowers our chatbot with natural language understanding and interactive capabilities. Seamlessly integrated into our project, Rasa allows our chatbot to comprehend and respond to user queries, providing a personalized and engaging experience. With its robust features and machine learning capabilities, Rasa enables us to deliver a cutting-edge chatbot that not only simplifies flight bookings but also enhances user interactions. Together with Rasa, our chatbot is at the forefront of transforming how users engage with our flight booking system, making it intuitive, dynamic, and user-centric."
      ],
      "metadata": {
        "id": "wKmUvnSV_6lX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ffcul5QcvbFr",
        "outputId": "84fd77b8-03da-4b31-b141-02d140092b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasa==3.4.5\n",
            "  Downloading rasa-3.4.5-py3-none-any.whl (824 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.0/824.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting CacheControl<0.13.0,>=0.12.9 (from rasa==3.4.5)\n",
            "  Downloading CacheControl-0.12.14-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: PyJWT[crypto]<3.0.0,>=2.0.0 in /usr/lib/python3/dist-packages (from rasa==3.4.5) (2.3.0)\n",
            "Collecting SQLAlchemy<1.5.0,>=1.4.0 (from rasa==3.4.5)\n",
            "  Downloading SQLAlchemy-1.4.51-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py<1.4,>=0.9 (from rasa==3.4.5)\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aio-pika<9.0.0,>=6.7.1 (from rasa==3.4.5)\n",
            "  Downloading aio_pika-8.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiogram<2.24 (from rasa==3.4.5)\n",
            "  Downloading aiogram-2.23.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp!=3.7.4.post0,<3.9,>=3.6 (from rasa==3.4.5)\n",
            "  Downloading aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting apscheduler<3.10,>=3.6 (from rasa==3.4.5)\n",
            "  Downloading APScheduler-3.9.1.post1-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs<22.2,>=19.3 (from rasa==3.4.5)\n",
            "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0,>=1.12 (from rasa==3.4.5)\n",
            "  Downloading boto3-1.34.19-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<2.3,>=1.2 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (2.2.1)\n",
            "Collecting colorclass<2.3,>=2.2 (from rasa==3.4.5)\n",
            "  Downloading colorclass-2.2.2-py2.py3-none-any.whl (18 kB)\n",
            "Collecting coloredlogs<16,>=10 (from rasa==3.4.5)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorhash<1.3.0,>=1.0.2 (from rasa==3.4.5)\n",
            "  Downloading colorhash-1.2.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting confluent-kafka<2.0.0,>=1.9.2 (from rasa==3.4.5)\n",
            "  Downloading confluent_kafka-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dask==2022.10.2 (from rasa==3.4.5)\n",
            "  Downloading dask-2022.10.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fbmessenger<6.1.0,>=6.0.0 (from rasa==3.4.5)\n",
            "  Downloading fbmessenger-6.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: google-auth<3 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (2.17.3)\n",
            "Collecting joblib<1.3.0,>=0.15.1 (from rasa==3.4.5)\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpickle<2.3,>=1.3 (from rasa==3.4.5)\n",
            "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting jsonschema<4.17,>=3.2 (from rasa==3.4.5)\n",
            "  Downloading jsonschema-4.16.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib<3.6,>=3.1 (from rasa==3.4.5)\n",
            "  Downloading matplotlib-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mattermostwrapper<2.3,>=2.2 (from rasa==3.4.5)\n",
            "  Downloading mattermostwrapper-2.2.tar.gz (2.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting networkx<2.7,>=2.4 (from rasa==3.4.5)\n",
            "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24.0,>=1.19.2 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (1.23.5)\n",
            "Collecting packaging<21.0,>=20.0 (from rasa==3.4.5)\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (1.3.0)\n",
            "Collecting prompt-toolkit<3.0.29,>=3.0 (from rasa==3.4.5)\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.2/380.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2 (from rasa==3.4.5)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psycopg2-binary<2.10.0,>=2.8.2 (from rasa==3.4.5)\n",
            "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<1.10.3 (from rasa==3.4.5)\n",
            "  Downloading pydantic-1.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot<1.5,>=1.4 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (1.4.2)\n",
            "Collecting pykwalify<1.9,>=1.7 (from rasa==3.4.5)\n",
            "  Downloading pykwalify-1.8.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pymongo[srv,tls]<3.11,>=3.8 (from rasa==3.4.5)\n",
            "  Downloading pymongo-3.10.1.tar.gz (715 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m715.9/715.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (2.8.2)\n",
            "Collecting python-engineio!=5.0.0,<6,>=4 (from rasa==3.4.5)\n",
            "  Downloading python_engineio-4.8.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-socketio<6,>=4.4 (from rasa==3.4.5)\n",
            "  Downloading python_socketio-5.11.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz<2023.0,>=2019.1 (from rasa==3.4.5)\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting questionary<1.11.0,>=1.5.1 (from rasa==3.4.5)\n",
            "  Downloading questionary-1.10.0-py3-none-any.whl (31 kB)\n",
            "Collecting randomname<0.2.0,>=0.1.5 (from rasa==3.4.5)\n",
            "  Downloading randomname-0.1.5.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rasa-sdk<3.5.0,>=3.4.1 (from rasa==3.4.5)\n",
            "  Downloading rasa_sdk-3.4.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting redis<5.0,>=3.4 (from rasa==3.4.5)\n",
            "  Downloading redis-4.6.0-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex<2022.11,>=2020.6 (from rasa==3.4.5)\n",
            "  Downloading regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0,>=2.23 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (2.31.0)\n",
            "Collecting rocketchat_API<1.29.0,>=0.6.31 (from rasa==3.4.5)\n",
            "  Downloading rocketchat_API-1.28.1-py3-none-any.whl (20 kB)\n",
            "Collecting ruamel.yaml<0.18.0,>=0.16.5 (from rasa==3.4.5)\n",
            "  Downloading ruamel.yaml-0.17.40-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sanic<21.13,>=21.12 (from rasa==3.4.5)\n",
            "  Downloading sanic-21.12.2-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sanic-cors<2.1.0,>=2.0.0 (from rasa==3.4.5)\n",
            "  Downloading Sanic_Cors-2.0.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting sanic-jwt<2.0.0,>=1.6.0 (from rasa==3.4.5)\n",
            "  Downloading sanic_jwt-1.8.0-py3-none-any.whl (23 kB)\n",
            "Collecting sanic-routing<0.8.0,>=0.7.2 (from rasa==3.4.5)\n",
            "  Downloading sanic_routing-0.7.2-py3-none-any.whl (23 kB)\n",
            "Collecting scikit-learn<1.2,>=0.22 (from rasa==3.4.5)\n",
            "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.9.0,>=1.4.1 (from rasa==3.4.5)\n",
            "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk<1.12.0,>=0.17.0 (from rasa==3.4.5)\n",
            "  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (67.7.2)\n",
            "Collecting sklearn-crfsuite<0.4,>=0.3 (from rasa==3.4.5)\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting slack-sdk<4.0.0,>=3.19.2 (from rasa==3.4.5)\n",
            "  Downloading slack_sdk-3.26.2-py2.py3-none-any.whl (284 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.1/284.1 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tarsafe<0.0.4,>=0.0.3 (from rasa==3.4.5)\n",
            "  Downloading tarsafe-0.0.3-py3-none-any.whl (5.0 kB)\n",
            "Collecting tensorflow<2.9.0,>=2.8.4 (from rasa==3.4.5)\n",
            "  Downloading tensorflow-2.8.4-cp310-cp310-manylinux2010_x86_64.whl (498.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-addons<0.18.0,>=0.17.0 (from rasa==3.4.5)\n",
            "  Downloading tensorflow_addons-0.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text<2.9.0,>=2.8.0 (from rasa==3.4.5)\n",
            "  Downloading tensorflow_text-2.8.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_hub<0.13.0,>=0.12.0 (from rasa==3.4.5)\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting terminaltables<3.2.0,>=3.1.0 (from rasa==3.4.5)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.31 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (4.66.1)\n",
            "Collecting twilio<7.15,>=6.26 (from rasa==3.4.5)\n",
            "  Downloading twilio-7.14.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from rasa==3.4.5) (4.5.0)\n",
            "Collecting typing-utils<0.2.0,>=0.1.0 (from rasa==3.4.5)\n",
            "  Downloading typing_utils-0.1.0-py3-none-any.whl (10 kB)\n",
            "Collecting ujson<6.0,>=1.35 (from rasa==3.4.5)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webexteamssdk<1.7.0,>=1.1.1 (from rasa==3.4.5)\n",
            "  Downloading webexteamssdk-1.6.1-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa==3.4.5) (8.1.7)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa==3.4.5) (2023.6.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa==3.4.5) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa==3.4.5) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from dask==2022.10.2->rasa==3.4.5) (0.12.0)\n",
            "Collecting aiormq~=6.6.3 (from aio-pika<9.0.0,>=6.7.1->rasa==3.4.5)\n",
            "  Downloading aiormq-6.6.4-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.10/dist-packages (from aio-pika<9.0.0,>=6.7.1->rasa==3.4.5) (1.9.4)\n",
            "Collecting Babel<2.10.0,>=2.9.1 (from aiogram<2.24->rasa==3.4.5)\n",
            "  Downloading Babel-2.9.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from aiogram<2.24->rasa==3.4.5) (2023.11.17)\n",
            "Collecting magic-filter>=1.0.9 (from aiogram<2.24->rasa==3.4.5)\n",
            "  Downloading magic_filter-1.0.12-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5) (1.3.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from apscheduler<3.10,>=3.6->rasa==3.4.5) (1.16.0)\n",
            "Requirement already satisfied: tzlocal!=3.*,>=2.0 in /usr/local/lib/python3.10/dist-packages (from apscheduler<3.10,>=3.6->rasa==3.4.5) (5.2)\n",
            "Collecting botocore<1.35.0,>=1.34.19 (from boto3<2.0,>=1.12->rasa==3.4.5)\n",
            "  Downloading botocore-1.34.19-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.12->rasa==3.4.5)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.12->rasa==3.4.5)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from CacheControl<0.13.0,>=0.12.9->rasa==3.4.5) (1.0.7)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs<16,>=10->rasa==3.4.5)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa==3.4.5) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa==3.4.5) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3->rasa==3.4.5) (4.9)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<4.17,>=3.2->rasa==3.4.5)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa==3.4.5) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa==3.4.5) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa==3.4.5) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa==3.4.5) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.6,>=3.1->rasa==3.4.5) (3.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.0.29,>=3.0->rasa==3.4.5) (0.2.12)\n",
            "Requirement already satisfied: cryptography>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from PyJWT[crypto]<3.0.0,>=2.0.0->rasa==3.4.5) (41.0.7)\n",
            "Collecting docopt>=0.6.2 (from pykwalify<1.9,>=1.7->rasa==3.4.5)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dnspython<2.0.0,>=1.16.0 (from pymongo[srv,tls]<3.11,>=3.8->rasa==3.4.5)\n",
            "  Downloading dnspython-1.16.0-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simple-websocket>=0.10.0 (from python-engineio!=5.0.0,<6,>=4->rasa==3.4.5)\n",
            "  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio<6,>=4.4->rasa==3.4.5) (0.22.1)\n",
            "Collecting fire (from randomname<0.2.0,>=0.1.5->rasa==3.4.5)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.23->rasa==3.4.5) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.23->rasa==3.4.5) (2.0.7)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml<0.18.0,>=0.16.5->rasa==3.4.5)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.0.10 (from sanic<21.13,>=21.12->rasa==3.4.5)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles>=0.6.0 (from sanic<21.13,>=21.12->rasa==3.4.5)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting websockets>=10.0 (from sanic<21.13,>=21.12->rasa==3.4.5)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp!=3.7.4.post0,<3.9,>=3.6->rasa==3.4.5)\n",
            "  Downloading multidict-5.2.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop>=0.5.3 (from sanic<21.13,>=21.12->rasa==3.4.5)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2,>=0.22->rasa==3.4.5) (3.2.0)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite<0.4,>=0.3->rasa==3.4.5)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite<0.4,>=0.3->rasa==3.4.5) (0.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<1.5.0,>=1.4.0->rasa==3.4.5) (3.0.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (23.5.26)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (3.9.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (1.14.1)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.9,>=2.8 (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (1.60.0)\n",
            "Collecting typeguard>=2.7 (from tensorflow-addons<0.18.0,>=0.17.0->rasa==3.4.5)\n",
            "  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from webexteamssdk<1.7.0,>=1.1.1->rasa==3.4.5) (0.18.3)\n",
            "Collecting requests-toolbelt (from webexteamssdk<1.7.0,>=1.1.1->rasa==3.4.5)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pamqp==3.2.1 (from aiormq~=6.6.3->aio-pika<9.0.0,>=6.7.1->rasa==3.4.5)\n",
            "  Downloading pamqp-3.2.1-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (0.42.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3.1->PyJWT[crypto]<3.0.0,>=2.0.0->rasa==3.4.5) (1.16.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=0.3.10->dask==2022.10.2->rasa==3.4.5) (1.0.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3->rasa==3.4.5) (0.5.1)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio!=5.0.0,<6,>=4->rasa==3.4.5)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (3.5.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (3.0.1)\n",
            "Collecting typing-extensions<5.0.0,>=4.1.1 (from rasa==3.4.5)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3.1->PyJWT[crypto]<3.0.0,>=2.0.0->rasa==3.4.5) (2.21)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (2.1.3)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto->simple-websocket>=0.10.0->python-engineio!=5.0.0,<6,>=4->rasa==3.4.5)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9.0,>=2.8.4->rasa==3.4.5) (3.2.2)\n",
            "Building wheels for collected packages: mattermostwrapper, randomname, docopt, fire, pymongo\n",
            "  Building wheel for mattermostwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mattermostwrapper: filename=mattermostwrapper-2.2-py3-none-any.whl size=2447 sha256=ba853549b3b611aa5862da4f471d61d778f713cd722519658794c838a47f41d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/dc/02/e3239f0ea0a676085826846d32ef09b10915c0a33c817d2dbb\n",
            "  Building wheel for randomname (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for randomname: filename=randomname-0.1.5-py3-none-any.whl size=58807 sha256=29d91ac3faa323bb6e71afd0c1ded3caada2bb295705ccd2db67ece9e5f960e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/df/c1/0bdf17c694217f49657ca36fd0239b9a243c34c27a70ff56ef\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=50268ed2711ce423a390006701a070ac7644f87b2551a88262f96d11a089f76c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=7776de47e23fab8ff3283ea8674273d071fb740beda0c5cce939f4829cd9690c\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for pymongo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymongo: filename=pymongo-3.10.1-cp310-cp310-linux_x86_64.whl size=462798 sha256=81cb8c729d81cb0418089b1095e49485fa3fb8046bb0d26b5902535fcee73194\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/ff/28/8624f4571ee5e095adb4057078b7bfc1d44d5d0a158d4f24bb\n",
            "Successfully built mattermostwrapper randomname docopt fire pymongo\n",
            "Installing collected packages: tensorflow-estimator, tensorboard-plugin-wit, sanic-routing, pytz, python-crfsuite, keras, docopt, confluent-kafka, websockets, uvloop, ujson, typing-utils, typing-extensions, terminaltables, tensorboard-data-server, tarsafe, SQLAlchemy, slack-sdk, sklearn-crfsuite, sentry-sdk, scipy, sanic-jwt, ruamel.yaml.clib, regex, redis, pyrsistent, pymongo, psycopg2-binary, protobuf, prompt-toolkit, pamqp, packaging, networkx, multidict, magic-filter, keras-preprocessing, jsonpickle, joblib, jmespath, humanfriendly, httptools, h11, fire, dnspython, colorhash, colorclass, Babel, attrs, apscheduler, aiofiles, absl-py, wsproto, typeguard, twilio, tensorflow_hub, scikit-learn, sanic, ruamel.yaml, rocketchat_API, requests-toolbelt, randomname, questionary, pydantic, mattermostwrapper, matplotlib, jsonschema, fbmessenger, dask, coloredlogs, CacheControl, botocore, webexteamssdk, tensorflow-addons, simple-websocket, sanic-cors, s3transfer, pykwalify, google-auth-oauthlib, aiormq, aiohttp, tensorboard, rasa-sdk, python-engineio, boto3, aiogram, aio-pika, tensorflow, python-socketio, tensorflow-text, rasa\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2023.3.post1\n",
            "    Uninstalling pytz-2023.3.post1:\n",
            "      Successfully uninstalled pytz-2023.3.post1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.24\n",
            "    Uninstalling SQLAlchemy-2.0.24:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.24\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2023.6.3\n",
            "    Uninstalling regex-2023.6.3:\n",
            "      Successfully uninstalled regex-2023.6.3\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 3.0.43\n",
            "    Uninstalling prompt-toolkit-3.0.43:\n",
            "      Successfully uninstalled prompt-toolkit-3.0.43\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.2\n",
            "    Uninstalling packaging-23.2:\n",
            "      Successfully uninstalled packaging-23.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.0.4\n",
            "    Uninstalling multidict-6.0.4:\n",
            "      Successfully uninstalled multidict-6.0.4\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 3.0.2\n",
            "    Uninstalling jsonpickle-3.0.2:\n",
            "      Successfully uninstalled jsonpickle-3.0.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: Babel\n",
            "    Found existing installation: Babel 2.14.0\n",
            "    Uninstalling Babel-2.14.0:\n",
            "      Successfully uninstalled Babel-2.14.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.2.0\n",
            "    Uninstalling attrs-23.2.0:\n",
            "      Successfully uninstalled attrs-23.2.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: tensorflow_hub\n",
            "    Found existing installation: tensorflow-hub 0.15.0\n",
            "    Uninstalling tensorflow-hub-0.15.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.15.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.2\n",
            "    Uninstalling jsonschema-4.19.2:\n",
            "      Successfully uninstalled jsonschema-4.19.2\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2023.8.1\n",
            "    Uninstalling dask-2023.8.1:\n",
            "      Successfully uninstalled dask-2023.8.1\n",
            "  Attempting uninstall: CacheControl\n",
            "    Found existing installation: CacheControl 0.13.1\n",
            "    Uninstalling CacheControl-0.13.1:\n",
            "      Successfully uninstalled CacheControl-0.13.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.9.1\n",
            "    Uninstalling aiohttp-3.9.1:\n",
            "      Successfully uninstalled aiohttp-3.9.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.1\n",
            "    Uninstalling tensorboard-2.15.1:\n",
            "      Successfully uninstalled tensorboard-2.15.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "bigframes 0.18.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "distributed 2023.8.1 requires dask==2023.8.1, but you have dask 2022.10.2 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.51 which is incompatible.\n",
            "jax 0.4.23 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "jaxlib 0.4.23+cuda12.cudnn89 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "plotnine 0.12.4 requires matplotlib>=3.6.0, but you have matplotlib 3.5.3 which is incompatible.\n",
            "referencing 0.32.1 requires attrs>=22.2.0, but you have attrs 22.1.0 which is incompatible.\n",
            "statsmodels 0.14.1 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "xarray 2023.7.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Babel-2.9.1 CacheControl-0.12.14 SQLAlchemy-1.4.51 absl-py-1.3.0 aio-pika-8.3.0 aiofiles-23.2.1 aiogram-2.23.1 aiohttp-3.8.6 aiormq-6.6.4 apscheduler-3.9.1.post1 attrs-22.1.0 boto3-1.34.19 botocore-1.34.19 colorclass-2.2.2 coloredlogs-15.0.1 colorhash-1.2.1 confluent-kafka-1.9.2 dask-2022.10.2 dnspython-1.16.0 docopt-0.6.2 fbmessenger-6.0.0 fire-0.5.0 google-auth-oauthlib-0.4.6 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 jmespath-1.0.1 joblib-1.2.0 jsonpickle-2.2.0 jsonschema-4.16.0 keras-2.8.0 keras-preprocessing-1.1.2 magic-filter-1.0.12 matplotlib-3.5.3 mattermostwrapper-2.2 multidict-5.2.0 networkx-2.6.3 packaging-20.9 pamqp-3.2.1 prompt-toolkit-3.0.28 protobuf-3.19.6 psycopg2-binary-2.9.9 pydantic-1.10.2 pykwalify-1.8.0 pymongo-3.10.1 pyrsistent-0.20.0 python-crfsuite-0.9.10 python-engineio-4.8.2 python-socketio-5.11.0 pytz-2022.7.1 questionary-1.10.0 randomname-0.1.5 rasa-3.4.5 rasa-sdk-3.4.1 redis-4.6.0 regex-2022.10.31 requests-toolbelt-1.0.0 rocketchat_API-1.28.1 ruamel.yaml-0.17.40 ruamel.yaml.clib-0.2.8 s3transfer-0.10.0 sanic-21.12.2 sanic-cors-2.0.1 sanic-jwt-1.8.0 sanic-routing-0.7.2 scikit-learn-1.1.3 scipy-1.8.1 sentry-sdk-1.11.1 simple-websocket-1.0.0 sklearn-crfsuite-0.3.6 slack-sdk-3.26.2 tarsafe-0.0.3 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.4 tensorflow-addons-0.17.1 tensorflow-estimator-2.8.0 tensorflow-text-2.8.2 tensorflow_hub-0.12.0 terminaltables-3.1.10 twilio-7.14.2 typeguard-4.1.5 typing-extensions-4.9.0 typing-utils-0.1.0 ujson-5.9.0 uvloop-0.19.0 webexteamssdk-1.6.1 websockets-12.0 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "matplotlib",
                  "mpl_toolkits",
                  "packaging",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install rasa==3.4.5 #installing a particular version of rasa as colab is only compatitable with this verison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "Vu4CYtxz_-oG",
        "outputId": "d645dc48-d539-4908-fd34-36860fb7834d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Collecting ipython\n",
            "  Downloading ipython-8.20.0-py3-none-any.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.2/809.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.6)\n",
            "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython)\n",
            "  Downloading prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.1/386.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (2.16.1)\n",
            "Collecting stack-data (from ipython)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython) (1.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.12)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting pure-eval (from stack-data->ipython)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n",
            "Installing collected packages: pure-eval, prompt-toolkit, jedi, executing, asttokens, stack-data, ipython\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 3.0.28\n",
            "    Uninstalling prompt-toolkit-3.0.28:\n",
            "      Successfully uninstalled prompt-toolkit-3.0.28\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.20.0 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.51 which is incompatible.\n",
            "rasa 3.4.5 requires prompt-toolkit<3.0.29,>=3.0, but you have prompt-toolkit 3.0.43 which is incompatible.\n",
            "rasa-sdk 3.4.1 requires prompt-toolkit<3.0.29,>=3.0, but you have prompt-toolkit 3.0.43 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-2.4.1 executing-2.0.1 ipython-8.20.0 jedi-0.19.1 prompt-toolkit-3.0.43 pure-eval-0.2.2 stack-data-0.6.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U ipython #it provides a rich architecture for interactive computing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFDqvlgqVEs0",
        "outputId": "ebfca416-b727-426a-aeca-69fe2719af4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting websockets==10.0\n",
            "  Downloading websockets-10.0.tar.gz (81 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/81.8 kB\u001b[0m \u001b[31m994.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: websockets\n",
            "  Building wheel for websockets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for websockets: filename=websockets-10.0-cp310-cp310-linux_x86_64.whl size=103014 sha256=f6a5ede04471cbc79fd9ee84a5c56b374c303194a75ccad1a4393f62f0133068\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/56/64/2ecbd74736716d6bba72d533296fac530c4530a84f932bcd81\n",
            "Successfully built websockets\n",
            "Installing collected packages: websockets\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 12.0\n",
            "    Uninstalling websockets-12.0:\n",
            "      Successfully uninstalled websockets-12.0\n",
            "Successfully installed websockets-10.0\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (1.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install websockets==10.0\n",
        "!pip install websocket-client  #it enhances our chatbot's real-time communication, providing users with instant updates and an interactive experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U2Szt_9xE6z",
        "outputId": "c489e77d-6328-40ff-a5a1-788762f8c86a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-15 02:49:01.915417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-01-15 02:49:01.915451: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2024-01-15 02:49:04.997345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-01-15 02:49:04.997774: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-01-15 02:49:04.998001: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-01-15 02:49:04.998174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-01-15 02:49:04.998336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-01-15 02:49:04.998631: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-01-15 02:49:04.998736: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (20.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm #spacy elevates our chatbot's natural language understanding, ensuring quick and precise responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kDKoNqcvUEFJ"
      },
      "outputs": [],
      "source": [
        "import spacy #importing spacy and creating a nlp attribute\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHVBIeez3cyR",
        "outputId": "87197191-0641-4118-8bfd-a3c0cf82f20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nest_asyncio==1.3.3\n",
            "  Downloading nest_asyncio-1.3.3-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: nest_asyncio\n",
            "  Attempting uninstall: nest_asyncio\n",
            "    Found existing installation: nest-asyncio 1.5.8\n",
            "    Uninstalling nest-asyncio-1.5.8:\n",
            "      Successfully uninstalled nest-asyncio-1.5.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclassic 1.0.0 requires nest-asyncio>=1.5, but you have nest-asyncio 1.3.3 which is incompatible.\n",
            "notebook 6.5.5 requires nest-asyncio>=1.5, but you have nest-asyncio 1.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nest_asyncio-1.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install nest_asyncio==1.3.3 #nest_asyncio optimizes our chatbot's asynchronous operations, enhancing efficiency and responsiveness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFVs_ym8EUTy",
        "outputId": "d9dd289d-be9d-42f4-f345-fc1a45bd2c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Event loop ready.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import rasa\n",
        "import nest_asyncio\n",
        "\n",
        "# Initialize the event loop\n",
        "nest_asyncio.apply()\n",
        "print(\"Event loop ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FZsqX3irEv7O"
      },
      "outputs": [],
      "source": [
        "# Initialize rasa\n",
        "from rasa.cli.scaffold import create_initial_project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KnIOywUKE6F5"
      },
      "outputs": [],
      "source": [
        "project = \"Air Ticket Counter Check Point\"\n",
        "create_initial_project(project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjxVHRJCE-u5",
        "outputId": "8b196710-7c11-4fe3-d682-5d17fc80779c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tests', 'domain.yml', 'actions', 'credentials.yml', 'config.yml', 'endpoints.yml', 'data']\n"
          ]
        }
      ],
      "source": [
        "# Construct the project path\n",
        "os.chdir(project)\n",
        "print(os.listdir(\".\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N_1uA1KPkBt",
        "outputId": "041b745e-318e-4042-d8ba-3285982dd033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yml data/ domain.yml models/\n"
          ]
        }
      ],
      "source": [
        "config = \"config.yml\"\n",
        "training_files = \"data/\"\n",
        "domain = \"domain.yml\"\n",
        "output = \"models/\"\n",
        "print(config, training_files, domain, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrdOIlziPxEo",
        "outputId": "82c96adc-60a6-4c1c-ef37-f39a3e7422fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasa/engine/caching.py:152: MovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base: DeclarativeMeta = declarative_base()\n",
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b(0lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk\u001b(B\n",
            "\u001b(0x\u001b(B Rasa Open Source reports anonymous usage telemetry to help improve the product \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B for all its users.                                                             \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B                                                                                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B If you'd like to opt-out, you can use `rasa telemetry disable`.                \u001b(0x\u001b(B\n",
            "\u001b(0x\u001b(B To learn more, check out https://rasa.com/docs/rasa/telemetry/telemetry.       \u001b(0x\u001b(B\n",
            "\u001b(0mqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj\u001b(B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94mThe configuration for pipeline and policies was chosen automatically. It was written into the config file at 'config.yml'.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasa/utils/tensorflow/model_data.py:774: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.concatenate(np.array(f)),\n",
            "Epochs: 100%|██████████| 100/100 [00:31<00:00,  3.18it/s, t_loss=1.13, i_acc=1]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 306.98it/s, # trackers=1]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 315.46it/s, # trackers=3]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 154.83it/s, # trackers=12]\n",
            "Processed story blocks: 100%|██████████| 3/3 [00:00<00:00, 66.85it/s, # trackers=39]\n",
            "Processed rules: 100%|██████████| 2/2 [00:00<00:00, 643.25it/s, # trackers=1]\n",
            "Processed trackers: 100%|██████████| 3/3 [00:00<00:00, 138.88it/s, # action=12]\n",
            "Processed actions: 12it [00:00, 671.97it/s, # examples=12]\n",
            "Processed trackers: 100%|██████████| 2/2 [00:00<00:00, 180.94it/s, # action=5]\n",
            "Processed actions: 5it [00:00, 1125.87it/s, # examples=4]\n",
            "Processed trackers: 100%|██████████| 3/3 [00:00<00:00, 219.95it/s, # action=12]\n",
            "Processed trackers: 100%|██████████| 2/2 [00:00<00:00, 1248.86it/s]\n",
            "Processed trackers: 100%|██████████| 5/5 [00:00<00:00, 701.04it/s]\n",
            "Processed trackers: 100%|██████████| 120/120 [00:00<00:00, 1032.17it/s, # action=30]\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/utils/tensorflow/model_data_utils.py:388: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.array(values), number_of_dimensions=4\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/utils/tensorflow/model_data_utils.py:404: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  MASK: [FeatureArray(np.array(attribute_masks), number_of_dimensions=3)]\n",
            "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "Epochs: 100%|██████████| 100/100 [00:16<00:00,  6.14it/s, t_loss=2.07, loss=1.91, acc=1]\n",
            "WARNING:rasa.shared.utils.common:The UnexpecTED Intent Policy is currently experimental and might change or be removed in the future 🔬 Please share your feedback on it in the forum (https://forum.rasa.com) to help us make this feature ready for production.\n",
            "Processed trackers: 100%|██████████| 120/120 [00:00<00:00, 1770.25it/s, # intent=12]\n",
            "Epochs: 100%|██████████| 100/100 [00:15<00:00,  6.30it/s, t_loss=0.125, loss=0.00759, acc=1]\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/core/policies/unexpected_intent_policy.py:839: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
            "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
            "  quantile_values = np.quantile(  # type: ignore[call-overload]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mYour Rasa model is trained and saved at 'models/20240115-025750-merciless-offset.tar.gz'.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainingResult(model='models/20240115-025750-merciless-offset.tar.gz', code=0, dry_run_results=None)\n"
          ]
        }
      ],
      "source": [
        "#Train the agent with the training data\n",
        "model_path = rasa.train(domain, config, [training_files], output)\n",
        "print(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "--XV_jksm6mN"
      },
      "outputs": [],
      "source": [
        "from rasa.jupyter import chat\n",
        "\n",
        "#endpoints = 'endpoints.yml'\n",
        "\n",
        "endpoints = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "RUCSgxbCo1Cq",
        "outputId": "2d32e852-3a51-48f1-f75b-8bf6e1b8f5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "WARNING:rasa.shared.utils.common:The UnexpecTED Intent Policy is currently experimental and might change or be removed in the future 🔬 Please share your feedback on it in the forum (https://forum.rasa.com) to help us make this feature ready for production.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your bot is ready to talk! Type your messages here or send '/stop'.\n",
            "hey\n",
            "\u001b[92mHey! How are you?\u001b[0m\n",
            "i am good\n",
            "\u001b[92mGreat, carry on!\u001b[0m\n",
            "what are you\n",
            "\u001b[92mI am a bot, powered by Rasa.\u001b[0m\n",
            "ok\n",
            "\u001b[92mGreat, carry on!\u001b[0m\n",
            "what is my name\n",
            "\u001b[92mHere is something to cheer you up:\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/nGF1K8f.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mDid that help you?\u001b[0m\n",
            "no\n",
            "/stop\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Start the conversation\n",
        "chat(model_path.model, endpoints)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data/config.yml\n",
        "\n",
        "version: \"3.1\"\n",
        "\n",
        "language: \"en\"\n",
        "\n",
        "pipeline:\n",
        "  - name: WhitespaceTokenizer\n",
        "  - name: RegexFeaturizer\n",
        "  - name: LexicalSyntacticFeaturizer\n",
        "  - name: CountVectorsFeaturizer\n",
        "  - name: CountVectorsFeaturizer\n",
        "    analyzer: \"char_wb\"\n",
        "    min_ngram: 1\n",
        "    max_ngram: 4\n",
        "  - name: DIETClassifier\n",
        "    epochs: 100\n",
        "  - name: EntitySynonymMapper\n",
        "  - name: ResponseSelector\n",
        "    epochs: 100\n",
        "\n",
        "policies:\n",
        "  - name: MemoizationPolicy\n",
        "  - name: TEDPolicy\n",
        "  # - name: UnexpecTEDIntentPolicy\n",
        "  - name: RulePolicy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQdhjGEmk5Zl",
        "outputId": "09ca94f4-af5d-414f-8942-00a5eb7f4921"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data/config.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbhgLbmZ78on",
        "outputId": "6e0413d6-2895-40d6-ba68-db54b42e279a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data/stories.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile data/stories.yml\n",
        "\n",
        "version: \"3.1\"\n",
        "\n",
        "stories:\n",
        "\n",
        "- story: check in\n",
        "  steps:\n",
        "    - intent: greet\n",
        "    - action: utter_greet\n",
        "    - intent: check_in\n",
        "    - action: utter_check_in\n",
        "\n",
        "\n",
        "- story: Luggage limit\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: luggage_limit\n",
        "  - action: utter_luggage_limit\n",
        "\n",
        "- story: cancel flight\n",
        "  steps:\n",
        "    - intent: greet\n",
        "    - action: utter_greet\n",
        "    - intent: cancel_flight\n",
        "    - action: utter_cancel_flight\n",
        "\n",
        "- story: policy\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: can_policy\n",
        "  - action: utter_can_policy\n",
        "\n",
        "- story: Take off time US\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: take_of_time\n",
        "  - action: utter_destination_conformation\n",
        "  - intent: destination_conformation_us\n",
        "  - action: utter_take_of_time_US\n",
        "\n",
        "- story: Take off time Canada\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: take_of_time\n",
        "  - action: utter_destination_conformation\n",
        "  - intent: destination_conformation_canada\n",
        "  - action: utter_take_of_time_canada\n",
        "\n",
        "- story: Landing time Us\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: landing_time\n",
        "  - action: utter_destination_conformation\n",
        "  - intent: destination_conformation_us\n",
        "  - action: utter_landing_time_us\n",
        "\n",
        "- story: Landing time Canada\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: landing_time\n",
        "  - action: utter_destination_conformation\n",
        "  - intent: destination_conformation_canada\n",
        "  - action: utter_landing_time_canada\n",
        "\n",
        "- story: Travel time Us\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: travel_time\n",
        "  - action: utter_destination_conformation\n",
        "  - intent: destination_conformation_us\n",
        "  - action: utter_travel_time_us\n",
        "\n",
        "- story: Travel time Canada\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: travel_time\n",
        "  - action: utter_destination_conformation\n",
        "  - intent: destination_conformation_canada\n",
        "  - action: utter_travel_time_canada\n",
        "\n",
        "- story: Seat booking economy\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: seat_booking\n",
        "  - action: utter_seat_booking_class\n",
        "  - intent: needed_economy\n",
        "  - action: utter_seat_availability_economy\n",
        "  - intent: num_seat\n",
        "  - action: utter_seat_economy\n",
        "\n",
        "- story: Seat booking business\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: seat_booking\n",
        "  - action: utter_seat_booking_class\n",
        "  - intent: needed_business\n",
        "  - action: utter_seat_availability_business\n",
        "  - intent: num_seat\n",
        "  - action: utter_seat_business\n",
        "\n",
        "- story: Departure gate canada\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: departure_gate\n",
        "  - action: utter_destination_conformation\n",
        "  - intent: destination_conformation_canada\n",
        "  - action: utter_departure_gate_canada\n",
        "\n",
        "- story: Departure gate us\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: departure_gate\n",
        "  - action: utter_destination_conformation\n",
        "  - intent: destination_conformation_us\n",
        "  - action: utter_departure_gate_us\n",
        "\n",
        "- story: upgrade_to_business_class\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: upgrade_to_business_class\n",
        "  - action: utter_upgrade_to_business_class\n",
        "\n",
        "- story: restricted items\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: restricted_items\n",
        "  - action: utter_restricted_items\n",
        "\n",
        "- story: happy path\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: mood_great\n",
        "  - action: utter_happy\n",
        "\n",
        "- story: sad path 1\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: mood_unhappy\n",
        "  - action: utter_cheer_up\n",
        "  - action: utter_did_that_help\n",
        "  - intent: affirm\n",
        "  - action: utter_happy\n",
        "\n",
        "- story: sad goodbye\n",
        "  steps:\n",
        "  - intent: greet\n",
        "  - action: utter_greet\n",
        "  - intent: mood_unhappy\n",
        "  - action: utter_cheer_up\n",
        "  - action: utter_did_that_help\n",
        "  - intent: deny\n",
        "  - action: utter_sad_goodbye\n",
        "\n",
        "- story: say goodbye\n",
        "  steps:\n",
        "  - intent: goodbye\n",
        "  - action: utter_goodbye\n",
        "\n",
        "- story: bot challenge\n",
        "  steps:\n",
        "  - intent: bot_challenge\n",
        "  - action: utter_iamabot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRdpw5prqaw1",
        "outputId": "10b4dece-904a-481b-b49d-586a452a94e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data/nlu.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile data/nlu.yml\n",
        "\n",
        "version: \"3.1\"\n",
        "\n",
        "nlu:\n",
        "- intent: check_in\n",
        "  examples: |\n",
        "    - I need to check in for my flight.\n",
        "    - Can I check in online?\n",
        "    - How do I go about checking in for my flight?\n",
        "    - Is online check-in available?\n",
        "    - I want to check in before my flight.\n",
        "    - What's the process for checking in?\n",
        "    - Do I need to check in at the airport?\n",
        "    - Can you help me with the check-in procedure?\n",
        "    - I'd like to check in online, please.\n",
        "\n",
        "- intent: luggage_limit\n",
        "  examples: |\n",
        "    - What is the luggage limit for this flight?\n",
        "    - What is the maximum weight of laggage I can carry?\n",
        "    - Is there a luggage limit for this flight?\n",
        "    - Can I carry 15kg of luggage for my travel?\n",
        "\n",
        "- intent: cancel_flight\n",
        "  examples: |\n",
        "    - How do I cancel my flight?\n",
        "    - Procedure of cancel a flight?\n",
        "    - Please cancel my flight.\n",
        "    - Can You please cancel my flight?\n",
        "\n",
        "- intent: can_policy\n",
        "  examples: |\n",
        "    - What is your cancellation policy?\n",
        "    - can you tell me about the cancellation policy of your flight?\n",
        "    - cancellation policy of your flight?\n",
        "    - Is there any cancellation plicy of your flight?\n",
        "    - cancellation Policy of your flight?\n",
        "\n",
        "- intent: take_of_time\n",
        "  examples: |\n",
        "    - At what time is the flight taking off?\n",
        "    - Is there a specific time for take off?\n",
        "    - When should I be at the boarding area?\n",
        "    - When is the take of time?\n",
        "\n",
        "- intent: destination_conformation_us\n",
        "  examples: |\n",
        "    - Yes, my destination is the United States.\n",
        "    - That's correct, I'm heading to the US.\n",
        "    - Confirming, my flight is to the United States.\n",
        "    - Yes, I'm flying to the US.\n",
        "    - Affirmative, my final destination is in the United States.\n",
        "    - That's right, I'm going to the United States.\n",
        "    - Yes, the US is my destination.\n",
        "    - Confirming, I'll be arriving in the United States.\n",
        "\n",
        "- intent: destination_conformation_canada\n",
        "  examples: |\n",
        "    - Yes, my destination is Canada.\n",
        "    - That's correct, I'm heading to Canada.\n",
        "    - Confirming, my flight is to Canada.\n",
        "    - Yes, I'm flying to Canada.\n",
        "    - Affirmative, my final destination is in Canada.\n",
        "    - That's right, I'm going to Canada.\n",
        "    - Yes, Canada is my destination.\n",
        "    - Confirming, I'll be arriving in Canada.\n",
        "\n",
        "- intent: landing_time\n",
        "  examples: |\n",
        "    - When will I land in my destination?\n",
        "    - At what time am I suppose to land?\n",
        "    - When will the flight end?\n",
        "    - When can I get off the flight?\n",
        "    - At what time does the flight end?\n",
        "\n",
        "- intent: travel_time\n",
        "  examples: |\n",
        "    - How long is the flight?\n",
        "    - can you tell me how long will i be in the flight?\n",
        "    - is this the longest flight?\n",
        "    - what is travel time\n",
        "    - how long does the flight takes?\n",
        "\n",
        "- intent: seat_booking\n",
        "  examples: |\n",
        "    - i want to book a seat on the flight?\n",
        "    - i need a seat for the flight?\n",
        "    - can i book a windown seat?\n",
        "    - i am trying to reserve a seat\n",
        "    - what are the seat option for this flight?\n",
        "\n",
        "- intent: needed_economy\n",
        "  examples: |\n",
        "    - I want to book a seat in economy class.\n",
        "    - Can you help me with booking an economy class seat?\n",
        "    - I prefer economy class for my flight.\n",
        "    - I need to reserve a seat in the economy section.\n",
        "    - Please book me a seat in the economy class.\n",
        "    - I'm looking to fly in the economy class.\n",
        "    - How can I book a seat in economy?\n",
        "\n",
        "- intent: needed_business\n",
        "  examples: |\n",
        "    - I would like to book a seat in the business class.\n",
        "    - Can you help me with reserving a business class seat?\n",
        "    - I prefer the business class for my flight.\n",
        "    - I need to book a seat in the business section.\n",
        "    - Please reserve a seat for me in the business class.\n",
        "    - I'm looking to fly in the business class.\n",
        "    - How can I book a seat in the business class?\n",
        "    - Business class booking, please.\n",
        "\n",
        "- intent: num_seat\n",
        "  examples: |\n",
        "    - i want to [2](number) seat\n",
        "    - is [3](number) seat available\n",
        "    - can i get the [9](number) seat\n",
        "    - [7](number) seat\n",
        "\n",
        "- intent: departure_gate\n",
        "  examples: |\n",
        "    - where is my departure gate\n",
        "    - where should i be to get on the flight\n",
        "    - from which gate does my flight departures\n",
        "    - departure gate\n",
        "\n",
        "- intent: upgrade_to_business_class\n",
        "  examples: |\n",
        "    - can i upgrade my flight to business class\n",
        "    - how can i upgrade my flight\n",
        "    - i want to travel in business class\n",
        "    - business class deals\n",
        "    - upgrade from economy to business\n",
        "\n",
        "- intent: restricted_items\n",
        "  examples: |\n",
        "    - can i bring a knife on the flight?\n",
        "    - what items are strictly not allowed\n",
        "    - is it possible to bring liquid substance\n",
        "    - what are prohibited from the flight\n",
        "    - restricted items\n",
        "\n",
        "- intent: greet\n",
        "  examples: |\n",
        "    - hey\n",
        "    - hello\n",
        "    - hi\n",
        "    - good morning\n",
        "    - good evening\n",
        "    - hey there\n",
        "\n",
        "- intent: goodbye\n",
        "  examples: |\n",
        "    - bye\n",
        "    - goodbye\n",
        "    - see you around\n",
        "    - see you later\n",
        "\n",
        "- intent: affirm\n",
        "  examples: |\n",
        "    - yes\n",
        "    - indeed\n",
        "    - of course\n",
        "    - that sounds good\n",
        "    - correct\n",
        "\n",
        "- intent: deny\n",
        "  examples: |\n",
        "    - no\n",
        "    - never\n",
        "    - I don't think so\n",
        "    - don't like that\n",
        "    - no way\n",
        "    - not really\n",
        "\n",
        "- intent: mood_great\n",
        "  examples: |\n",
        "    - perfect\n",
        "    - very good\n",
        "    - great\n",
        "    - amazing\n",
        "    - wonderful\n",
        "    - I am feeling very good\n",
        "    - I am great\n",
        "    - I'm good\n",
        "\n",
        "- intent: mood_unhappy\n",
        "  examples: |\n",
        "    - sad\n",
        "    - very sad\n",
        "    - unhappy\n",
        "    - bad\n",
        "    - very bad\n",
        "    - awful\n",
        "    - terrible\n",
        "    - not very good\n",
        "    - extremely sad\n",
        "    - so sad\n",
        "\n",
        "- intent: bot_challenge\n",
        "  examples: |\n",
        "    - are you a bot?\n",
        "    - are you a human?\n",
        "    - am I talking to a bot?\n",
        "    - am I talking to a human?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''!pip install dlib\n",
        "!pip install deepface\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import dlib\n",
        "from deepface import DeepFace\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZhJVDNPIEqnC",
        "outputId": "98f469f9-2c24-4e89-99cc-b629bc021217"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"!pip install dlib\\n!pip install deepface\\n\\nimport cv2\\nimport os\\nimport dlib\\nfrom deepface import DeepFace\\n\\nfrom google.colab import drive\\ndrive.mount('/content/gdrive')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''# actions.py\n",
        "\n",
        "from rasa_sdk import Action, Tracker\n",
        "from rasa_sdk.executor import CollectingDispatcher\n",
        "from deepface import DeepFace\n",
        "\n",
        "class VerifyThePassengerAction(Action):\n",
        "    def name(self):\n",
        "        return \"verify_the_passenger\"\n",
        "\n",
        "    async def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: dict) -> list:\n",
        "\n",
        "        passport_number = tracker.get_slot(\"passport_number\")\n",
        "        booking_reference = tracker.get_slot(\"booking_reference\")\n",
        "\n",
        "        verification_result = self.face_recognition_verification(passport_number)\n",
        "\n",
        "        if verification_result:\n",
        "            dispatcher.utter_message(\"Face recognition successful. How can I assist you with your check-in?\")\n",
        "        else:\n",
        "            dispatcher.utter_message(\"Face recognition failed. Please check your face and try again.\")\n",
        "\n",
        "        return []\n",
        "\n",
        "    def face_recognition_verification(self, passport_number):\n",
        "\n",
        "        img1_path = f\"/content/gdrive/Othercomputers/My Laptop (1)/Sampel/PP Image/{passport_number}\"\n",
        "        img2_path = f\"/content/gdrive/Othercomputers/My Laptop (1)/Sampel/Current Image/{passport_number}\"\n",
        "\n",
        "        result = DeepFace.verify(img1_path=img1_path, img2_path=img2_path)\n",
        "        face_verification_result = result['verified']\n",
        "\n",
        "        return face_verification_result'''\n"
      ],
      "metadata": {
        "id": "Ji7LYSRh2dhW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "a9432da6-b93a-4e90-b0bb-64b385aeead0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# actions.py\\n\\nfrom rasa_sdk import Action, Tracker\\nfrom rasa_sdk.executor import CollectingDispatcher\\nfrom deepface import DeepFace\\n\\nclass VerifyThePassengerAction(Action):\\n    def name(self):\\n        return \"verify_the_passenger\"\\n\\n    async def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: dict) -> list:\\n\\n        passport_number = tracker.get_slot(\"passport_number\")\\n        booking_reference = tracker.get_slot(\"booking_reference\")\\n\\n        verification_result = self.face_recognition_verification(passport_number)\\n\\n        if verification_result:\\n            dispatcher.utter_message(\"Face recognition successful. How can I assist you with your check-in?\")\\n        else:\\n            dispatcher.utter_message(\"Face recognition failed. Please check your face and try again.\")\\n\\n        return []\\n\\n    def face_recognition_verification(self, passport_number):\\n\\n        img1_path = f\"/content/gdrive/Othercomputers/My Laptop (1)/Sampel/PP Image/{passport_number}\"\\n        img2_path = f\"/content/gdrive/Othercomputers/My Laptop (1)/Sampel/Current Image/{passport_number}\"\\n\\n        result = DeepFace.verify(img1_path=img1_path, img2_path=img2_path)\\n        face_verification_result = result[\\'verified\\']\\n\\n        return face_verification_result'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2rgJBWcsN_F",
        "outputId": "5b8846a6-f14e-4f64-f2a5-f699bdf8a49c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting domain.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile domain.yml\n",
        "\n",
        "version: \"3.1\"\n",
        "\n",
        "\n",
        "\n",
        "intents:\n",
        "  - check_in\n",
        "  - luggage_limit\n",
        "  - cancel_flight\n",
        "  - can_policy\n",
        "  - take_of_time\n",
        "  - destination_conformation_us\n",
        "  - destination_conformation_canada\n",
        "  - landing_time\n",
        "  - seat_booking\n",
        "  - needed_economy\n",
        "  - needed_business\n",
        "  - travel_time\n",
        "  - restricted_items\n",
        "  - num_seat\n",
        "  - departure_gate\n",
        "  - upgrade_to_business_class\n",
        "  - greet\n",
        "  - goodbye\n",
        "  - affirm\n",
        "  - deny\n",
        "  - mood_great\n",
        "  - mood_unhappy\n",
        "  - bot_challenge\n",
        "\n",
        "responses:\n",
        "\n",
        "  utter_check_in:\n",
        "  - text: \"Please wait until our agent connect with you\"\n",
        "\n",
        "  utter_luggage_limit:\n",
        "  - text: '''You can check in as many bags as you like up to the weight allowance for your travel class. Each individual bag must not weigh more than 32kg (for mor details please log in to our website)'''\n",
        "\n",
        "  utter_can_policy:\n",
        "  - text: \"Please log in to our website to get full details about our policy\"\n",
        "\n",
        "  utter_cancel_flight:\n",
        "  - text: \"Your ticket cancelation request sent successfully, Please wait until our agent connect with you\"\n",
        "\n",
        "  utter_destination_conformation:\n",
        "  - text: \"Please confirm your destination is it to Us or Canada\"\n",
        "\n",
        "  utter_take_of_time_US:\n",
        "  - text: \"Every day our flight to US take of at 9:00 am \"\n",
        "\n",
        "  utter_take_of_time_canada:\n",
        "  - text: \"Every day our flight to US take of at 4:00 pm\"\n",
        "\n",
        "  utter_landing_time_canada:\n",
        "  - text: \"Every day our flight to US land in New York International Airport at 11:00am (in local time)\"\n",
        "\n",
        "  utter_landing_time_us:\n",
        "  - text: \"Every day our flight to canada lands in Halifax Stanfield International Airport at 06:00pm (in local time)\"\n",
        "\n",
        "  utter_travel_time_canada:\n",
        "  - text: \"Travel time from London to New York International Airport is 3 hours\"\n",
        "\n",
        "  utter_travel_time_us:\n",
        "  - text: \"Travel time from London to Halifax Stanfield International Airpor is 3 hours\"\n",
        "\n",
        "  utter_seat_booking_class:\n",
        "  - text: \"Which class do you prefer Economy or Business\"\n",
        "\n",
        "  utter_seat_availability_economy:\n",
        "  - text: \"We have only few seats remaining in economy class please book your seat as soon as possible\"\n",
        "\n",
        "  utter_seat_economy:\n",
        "  - text: \"Your economy class seat booking conformation is successfully submited, Please wait until our agent connects with you\"\n",
        "\n",
        "  utter_seat_availability_business:\n",
        "  - text: \"We have only few seats remaining in business class please book your seat as soon as possible\"\n",
        "\n",
        "  utter_seat_business:\n",
        "  - text: \"Your business class seat booking conformation is successfully submited, Please wait until our agent connects with you\"\n",
        "\n",
        "  utter_departure_gate_canada:\n",
        "  - text: \"Departure gate for passengers who are traveling to Canada is gate No.C5\"\n",
        "\n",
        "  utter_departure_gate_us:\n",
        "  - text: \"Departure gate for passengers who are traveling to US is gate No.A12\"\n",
        "\n",
        "  utter_restricted_items:\n",
        "  - text: \"Please log in to our website to get full details about restricted items\"\n",
        "\n",
        "  utter_upgrade_to_business_class:\n",
        "  - text: \"Please wait until our agent connect with you\"\n",
        "\n",
        "  utter_greet:\n",
        "  - text: \"Hey! Welcome to our Air line, How may i help you?\"\n",
        "\n",
        "  utter_cheer_up:\n",
        "  - text: \"Here is something to cheer you up:\"\n",
        "    image: \"https://i.imgur.com/nGF1K8f.jpg\"\n",
        "\n",
        "  utter_did_that_help:\n",
        "  - text: \"Did that help you?\"\n",
        "\n",
        "  utter_happy:\n",
        "  - text: \"Great, carry on!\"\n",
        "\n",
        "  utter_goodbye:\n",
        "  - text: \"Bye\"\n",
        "\n",
        "  utter_sad_goodbye:\n",
        "  - text: \"Bye\"\n",
        "\n",
        "  utter_iamabot:\n",
        "  - text: \"I am a bot, powered by Rasa.\"\n",
        "\n",
        "entities:\n",
        "  - number\n",
        "\n",
        "\n",
        "session_config:\n",
        "  session_expiration_time: 60\n",
        "  carry_over_slots_to_new_session: true\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp5XVt3Gam9g",
        "outputId": "ca802d3e-4493-4f1a-92cd-42161b99ee0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94mThe configuration for pipeline and policies was chosen automatically. It was written into the config file at 'config.yml'.\u001b[0m\n",
            "\u001b[92mYour Rasa model is trained and saved at 'models/20240115-030640-cold-accuracy.tar.gz'.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainingResult(model='models/20240115-030640-cold-accuracy.tar.gz', code=0, dry_run_results=None)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train a ML model\n",
        "model_path = rasa.train(domain, config, [training_files], output)\n",
        "print(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "W2CiToecSt6V"
      },
      "outputs": [],
      "source": [
        "from rasa.jupyter import chat\n",
        "#endpoints = 'endpoints.yml'\n",
        "\n",
        "endpoints = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1nCBzU_X-hM",
        "outputId": "b16d7c26-590b-4b58-8081-797f9e07a998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Reshape:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/gradients/cond/GatherV2_grad/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/cond_1_grad/Identity_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/cond_1_grad/Identity:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradients/cond_1_grad/Identity_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "WARNING:rasa.shared.utils.common:The UnexpecTED Intent Policy is currently experimental and might change or be removed in the future 🔬 Please share your feedback on it in the forum (https://forum.rasa.com) to help us make this feature ready for production.\n",
            "WARNING:tensorflow:5 out of the last 35 calls to <bound method RasaModel.predict_step of <rasa.core.policies.ted_policy.TED object at 0x793fc604ee30>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your bot is ready to talk! Type your messages here or send '/stop'.\n",
            "hey\n",
            "\u001b[92mHey! Welcome to our Air line, How may i help you?\u001b[0m\n",
            "I am looking to book a flight \n",
            "\u001b[92mWhich class do you prefer Economy or Business\u001b[0m\n",
            "business please\n",
            "\u001b[92mWe have only few seats remaining in business class please book your seat as soon as possible\u001b[0m\n",
            "okay\n",
            "\u001b[92mWhich class do you prefer Economy or Business\u001b[0m\n",
            "business\n",
            "\u001b[92mWe have only few seats remaining in business class please book your seat as soon as possible\u001b[0m\n",
            "okay what are the restricted items in the flight\n",
            "\u001b[92mPlease log in to our website to get full details about restricted items\u001b[0m\n",
            "okay\n",
            "\u001b[92mWhich class do you prefer Economy or Business\u001b[0m\n",
            "what\n",
            "\u001b[92mWhich class do you prefer Economy or Business\u001b[0m\n",
            "no\n",
            "\u001b[92mBye\u001b[0m\n",
            "ok\n",
            "\u001b[92mHey! Welcome to our Air line, How may i help you?\u001b[0m\n",
            "shut up\n",
            "\u001b[92mWhich class do you prefer Economy or Business\u001b[0m\n",
            "please\n",
            "\u001b[92mWhich class do you prefer Economy or Business\u001b[0m\n",
            "/stop\n"
          ]
        }
      ],
      "source": [
        "chat(model_path.model, endpoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbxxBbmeZmTt",
        "outputId": "4bd96f27-6714-498a-95c3-2821a8fc5b2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmpd9sp4v2z /tmp/tmpp3c6q7ct\n",
            "Done testing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/rasa/api.py:143: RuntimeWarning: coroutine 'test_core' was never awaited\n",
            "  test_core(model, stories, output, additional_arguments)  # type: ignore[unused-coroutine] # noqa: E501\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/rasa/api.py:144: RuntimeWarning: coroutine 'test_nlu' was never awaited\n",
            "  test_nlu(model, nlu_data, output, additional_arguments)  # type: ignore[unused-coroutine] # noqa: E501\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ],
      "source": [
        "import rasa.shared.data as data\n",
        "nlu_data_directory = data.get_nlu_directory(training_files)\n",
        "stories_directory = data.get_core_directory(training_files)\n",
        "print(stories_directory, nlu_data_directory)\n",
        "rasa.test(model_path, stories_directory, nlu_data_directory)\n",
        "print(\"Done testing.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bicA15zN4Asv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}